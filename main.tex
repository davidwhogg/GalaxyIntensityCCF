\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath,amsfonts,mathrsfs}

% typesetting generalities
\linespread{1.08}
\sloppy\sloppypar\raggedbottom
\frenchspacing % Don't even think about removing this.
\pagestyle{myheadings}
\markboth{foo}{\textsc{the galaxy--intensity cross-correlation function}}
\bibliographystyle{plain}

% text macros
\newcommand{\sectionname}{Section}
\newcommand{\secref}[1]{\sectionname~\ref{#1}}
\newcommand{\project}[1]{\textsl{#1}}

% math macros
\newcommand{\setof}[1]{\left\{{#1}\right\}}
\newcommand{\set}[1]{\mathscr{#1}}

\title{\bfseries%
Broken robots:\\
The projected three-dimensional cross-correlation of electromagnetic intensity and galaxies}
\author{David~W.~Hogg, {\itshape writing for Nada~El-Falou, Dustin~Lang,} \\ {\itshape Elena~Pinetti, Juna~Kollmeier, and others}}
\date{2025 September}

\begin{document}

\maketitle

\section*{History and context of this document}
\begin{itemize}
\item DL pointed out to DWH that the \project{DESI} fiber positioning robot system has quite a few broken robots.
  These robots hold functional spectroscopic fibers but are parked in the focal plane.
  Thus, as \project{DESI} observes tiles, these broken-robot fibers represent something very close to a perfectly randomly targeted (in a celestial-coordinates sense) spectroscopic survey (in fact there is a tiny bit of non-randomness, and that non-randomness is, in fact, DL's fault).
\item DL has shown that, if you average these broken-fiber spectra as a function of angular separation from the nearest luminous galaxy, un-redshifted to the nearest-galaxy redshift, you can see emission lines like H-alpha and [OII] correlated with galaxies.
  This inspired a project with these fibers and NEF, which in turn inspired this note.
\item
  This note attempts to formalize this ``averaging'' of spectra into a well-defined statistic, which can be the real-space, 2-d projection of the 3-d cross-correlation function between galaxies and photons, or the angular, 2-d cross-correlation function between galaxies and photons.
  These functions will produce redshift-deconvolved correlated intensity as a function of wavelength and separation.
  Hogg believes that these functions can be interpreted in terms of the global (clustered) density of star formation and stellar mass.
  They might also show anomalous line emission or absorption correlated with galaxies that could be attributed to new physics in the dark sector (decay, de-excitation, photon conversion, photon scattering, or other effects).
  They have superior statistical properties to more na\"ive spectral averages.
\item Separately, EP has been looking for anomalous line emission in \project{JWST} spectroscopic imaging (IFU) data.
  She has been looking at the Milky Way halo exclusively, in part because the redshift is then known (to be essentially zero), and the data can be stacked or averaged.
  She has been using individual \project{JWST} pointings as data, but some of the \project{JWST} instruments are IFUs and can produce many spectra per pointing.
\item In addition to the \project{JWST} and \project{DESI} data, there are relevant data from \project{SDSS-V LVM}, and it would be possible to propose for additional \project{LVM} tiles to improve any measurement of this type with \project{LVM}.
\item There is an open question of whether these methods can be extended to objective-grism observations from \project{JWST}, \project{Euclid}, and \project{Roman}.
  In principle this sounds impossible, because celestial position is mixed with wavelength in the fully-overlapping focal plane, but I have thoughts and feelings.
\item There have been projects that have performed related angular cross-correlations in an average large-scale cross-correlation power spectrum sense between \project{Fermi} and \project{Planck}.
  No-one has done the cross-correlation in real-space, no-one has done it with the proposed data sets, and no-one has done it to small angular and small linear scales.
  To my knowledge, no-one has realized that this statistic exists, nor that it can effectively deconvolve the redshifts of the spectra.
  Even the spectral averaging performed by DL are novel, I believe.
\end{itemize}


\section{Introduction}\label{sec:intro}
Stuff about clusters, quasars, galaxies, stars, dust, gas, and DM all being shown to be strongly correlated with galaxies, out to large radii.

Why do electromagnetic intensity? Because we can. And it is a fundamental invariant of electromagnetism in a transparent universe.

Note that we are using sky spectra here. But we could be using ANY spectra, provided that we can subtract out of them their principal targets, and those principal targets are either background to, or else transparent to, the redshifts we want to investigate.

\section{Setup and assumptions}\label{sec:setup}
We have a catalog from a redshift survey of galaxies, which contains $M$ galaxies $j$, with $1\leq j\leq M$, each of which has an accurately measured two-dimensional angular position $\alpha_j$, an accurately measured redshift $z_j$, and a set of other measured properties $Q_j$ (which might include luminosity, color, star-formation rate, stellar mass, or other measurements or inferences).
In what follows, the set $\set{G}=\setof{\alpha_j, z_j}_{j=1}^M$ of position--redshift pairs is the \emph{galaxy set}.
In what follows we will assume that the celestial positions $z_j$ and redshifts $z_j$ are both known so accurately that we don't need to track uncertainties on either.

We will assume that this galaxy sample is well selected and has sensible properties for the purposes of subsequent interpretations of the signals we find.
Interestingly, we do not need to know what's commonly called the ``window function'' for this sample; we don't need to know what sky footprint was used for the selection of the sample.
Also, we are using the word ``galaxy'' but these could be quasars or x-ray selected clusters or any other kinds of cosmological objects.

Actually there is one thing that we need to know about the window function:
We need a fake or \emph{random galaxy set} $\set{G}_R$ that contains $\beta\,M$ entries, with $\beta>1$.
This set contains entries $\setof{\alpha_k,z_k}_{k=1}^{\beta M}$ with the same window function as the real galaxy set $\set{G}$ but no other spatial structure.
In \secref{sec:method} we will describe methods for making this random set without having any explicit form for the window function, under the particular assumption that the selection function that sets the redshift distribution $p(z)$ does not depend strongly on the sky position $\alpha$.

In addition, we have a set of $N$ spectra $f_i$, with $1\leq i\leq N$, taken at known two-dimensional sky positions $\alpha_i$.
We will assume that these spectra are (at least approximately) wavelength calibrated, spectro-photometrically calibrated, and sky-subtracted.
In what follows we will think of the spectra $f_i$ as being functions of (logarithmic) observed-frame wavelength, possibly represented as values on a grid of extracted wavelengths.
We will assume that the celestial positions $\alpha_i$ are very accurately known, but we will assume that the spectra $f_i$ are noisily known.
That is, each spectrum $f_i(\ln\lambda)$, seen as a function of logarithmic wavelength $\ln\lambda$ has associated with it a weight function $W_i(\ln\lambda)$ which says, at each wavelength, how precisely we have measured the spectrum.
These weights can be seen as inverse variances.
Or they can be seen as products of exposure times with effective areas.
They are supposed to represent the sensitivity (in an inverse-variance sense) of each measurement $f_i(\ln\lambda)$ at every wavelength $\lambda$.
In what follows, the set $\set{S}=\setof{\alpha_i, f_i, W_i}_{i=1}^N$ of position--spectrum--weight triples is the \emph{spectrum set}.

The spectro-photometric calibration requirements are not strong, but the project will work better as the spectra get closer to being calibrated.
We will think of the spectra as being calibrated in intensity units (energy per time per area per wavelength per solid angle of the fiber or aperture) or else the same but with photons instead of energy.
Most of our data sources calibrate to \emph{flux} not intensity, but since these two quantities are related by the solid-angles of the spectral apertures, we can convert everything to intensity units, and we do.
Alternatively, the spectra could be in photon phase-space density units---this is also an invariant---but we will stay classical in what follows.
The wavelength-calibration and sky-subtraction requirements are relatively strong however:
Variance in wavelength calibration and sky subtraction will reduce the signal-to-noise of the signals we seek.

The most important assumption we will make about these $N$ spectra is that the celestial positions $\alpha_i$ at which the spectra were taken are not directly related---neither biased towards or away from---the celestial positions $\alpha_j$ at which the galaxies are found.
That is, there is a statistical independence of the ``footprints'' of the galaxy set and the spectral placement.

In addition to the spectral set $\set{S}$ we will need a \emph{random spectrum set} $\set{S}_R=\setof{\alpha_k,f_k,W_k}_{k=1}^{\beta N}$, again larger than the real spectral set by a factor of $\beta$.
Again we can make this directly from the spectral set provided that the selection procedure that effectively sets the spectrum distribution $p(f)$ and the weight distribution $p(W)$ does not depend on the sky position $\alpha$.
This $\beta$ doesn't have to be the same as the $\beta$ for the random galaxy set above, but it reduces our number of arbitrary choices if it is.

HOGG: There is a two-point function in real space. There is a two-point function in redshift space. There are projections of this that are observable, and which are measured and then deprojected in present-day large-scale structure projects. This is what we will measure.

HOGG: Note that everything is linear in the galaxies, and everything is linear in the spectra. So you can see this project as a sum over galaxies of one-galaxy surveys. Or a sum over spectra of one-spectrum measurements.

In addition, we will assume that the background cosmological model is known precisely enough, and there are not pathologies like strong lensing significantly in play.

\section{Methods and results}\label{sec:method}
Fundamentally, the method is
\begin{align}
    w_m(\ln\lambda) &= \frac{DD_m(\ln\lambda) - DR_m(\ln\lambda) - RD_m(\ln\lambda) + RR_m(\ln\lambda)}{RR^\text{(d)}_m(\ln\lambda)} ~,\label{eq:ls}
\end{align}
where $w_m(\ln\lambda)$ is the value of the two-dimensional projected real-space cross-correlation function (between intensity and galaxies), with units of intensity, as a function of logarithmic wavelength $\ln\lambda$ in a projected real-space transverse radius bin indexed by $m$.
The four numerator terms on the RHS are defined as
\begin{align}
    DD_m(\ln\lambda) &= 
    \sum_{j\in\set{G}}\sum_{i\in\set{S}} Q(i,j;m)\,W_i(\ln\lambda-\Delta_j)\,f_i(\ln\lambda-\Delta_j) \\
    DR_m(\ln\lambda) &= 
    \sum_{j\in\set{G}}\sum_{k\in\set{S}_R} Q(k,j;m)\,W_k(\ln\lambda-\Delta_j)\,f_k(\ln\lambda-\Delta_j) \\
    RD_m(\ln\lambda) &= 
    \sum_{k\in\set{G}_R}\sum_{i\in\set{S}} Q(i,k;m)\,W_i(\ln\lambda-\Delta_k)\,f_i(\ln\lambda-\Delta_k) \\
    RR_m(\ln\lambda) &= 
    \sum_{k\in\set{G}_R}\sum_{k'\in\set{S}_R} Q(k',k;m)\,W_{k'}(\ln\lambda-\Delta_k)\,f_{k'}(\ln\lambda-\Delta_k) \\
    RR^\text{(d)}_m(\ln\lambda) &= 
    \sum_{k\in\set{G}_R}\sum_{k'\in\set{S}_R} Q(k',k;m)\,W_{k'}(\ln\lambda-\Delta_k) \\
    Q(i,j;m) &\equiv\left\{\begin{array}{l}1~~\text{if}~~r_{m-1}<D_{A,j}\,|\alpha_i-\alpha_j|\leq r_m \\ 0~~\text{otherwise}\end{array}\right.~,
\end{align}
where
$Q()$ is an indicator function used to put ones on pairs that are ``in the bin'' and zeros on pairs that aren't,
$r_m$ is the real-space proper radius of the outer edge of bin $m$,
$D_{A,j}$ is the angular diameter distance (in the fiducial world model) to galaxy $j$,
the spectra $f_i$ and weights $W_i$ are being treated as functions of logarithmic wavelength (which maybe can be interpolated sensibly),
and $\Delta_j$ is the log-wavelength Doppler shift corresponding to the redshift of galaxy $j$.
Because the Doppler shifts appear in the arguments of the $f_i$ and $W_i$ functions, there is an interpolation question.
HOGG RECOMMENDS that we just do nearest-neighbor interpolation to start!
This works well with the \project{DESI} or \project{LVM} wavelength grids, which are logarithmically spaced with a good spacing.

HOGG SAY: The above expressions are missing some factors of $[1+z]^{-q}$, where $q=3,4,5$, depending on what the intensity is ``per unit of'' in the wavelength or frequency or log-energy direction.

HOGG SAY: Does this \emph{really} work with the weights being non-trivial?
At most they should be just effective areas times exposure times, I think, not the inverses of empirical root-N uncertainties.

HOGG SAY: Do we want to work in proper distance (as given above) or comoving distance?
We might even want to work in some distance coordinate that is scaled to the growth of large-scale structure!

Sometimes the window functions are known explicitly.
In this case, the random galaxy set and random spectrum set can both be made directly from these explicit window functions.
If the window functions are not known, but it is believed that the selection function that sets the distribution $p(z)$ of galaxy redshifts in the sample does not depend on sky position $\alpha$, and if it is believed that the selection function that sets the distribution $p(f)$ of spectra and the distribution $p(W)$ of weights obtained also does not depend on sky position $\alpha$, then there are ways to make the random sets empirically.
Here are two:
In one, the random galaxy set $\set{G}_R$ is made by performing $\beta M$ independent draws (with replacement) from the real data positions $\alpha_j$ and then making the same number of (again) independent draws from the redshifts $z_j$.
The random spectrum set $\set{S}_R$ is made similarly but with $\beta N$ draws from the $\alpha_i$ and $\beta N$ draws from the $(f_i, W_i)$ pairs.
That is, the positions are randomized relative to the spectra, but the weights stay with their associated spectra.
The other method involves slightly non-independent draws:
Copy each catalog (galaxies and spectra) $\beta$ times to make a bigger catalog, with every entry repeated exactly $\beta$ times.
Then, for the galaxies, randomly shuffle the redshifts $z_k$ relative to the sky positions $\alpha_k$ to make $\set{G}_R$,
and, for the spectra, randomly shuffle the spectra $f_k$ relative to the sky positions $\alpha_k$ to make $\set{S}_R$. 
That is, don't make the catalogs with random independent draws with replacement, but instead have every true position and true redshift and true spectrum appear exactly $\beta$ times in each random catalog.
HOGG BELIEVES that the latter choice (the less independent choice) will reduce the variance of the estimator.
It might also bias it, at least slightly?

If you think about the estimated cross-correlation function $w_m(\ln\lambda)$ as a kind of mean spectrum of untargeted galaxies that are correlated with the targeted galaxies in the galaxy set, then other forms or estimators for $w_m(\ln\lambda)$ suggest themselves.
Two that come to mind are
\begin{align}
    w_m(\ln\lambda) &= \frac{DD_m(\ln\lambda) - DR_m(\ln\lambda)}{DR^\text{(d)}_m(\ln\lambda)} \\
    w_m(\ln\lambda) &= \frac{DD_m(\ln\lambda) - RD_m(\ln\lambda)}{RD^\text{(d)}_m(\ln\lambda)} ~.
\end{align}
These two forms may be just as good as method \eqref{eq:ls} above, and may be easier to compute for various pragmatic reasons.
HOGG SAY: IF we appropriately define the denominator terms with superscript ``(d)'', these will become background-subtracted mean intensities, or ``average spectra''.

HOGG SAY: Technically the cross-correlation function should be dimensionless!
These expressions have units of intensity $f$.
For this reason, these expressions are more like mean spectra than cross-correlation functions.
If we truly want the dimensionless cross-correlation function, the estimator \eqref{eq:ls} ought to be divided by $RR_m(\ln\lambda)$.

HOGG SAY: What changes if you go to a natively 2-d angular cross-correlation framework?
I don't think this is a good idea, but it is a thing that has been measured (see papers about \project{Fermi} and \project{Planck}).

\section{Discussion}\label{sec:discussion}

\paragraph{Acknowledgments}

\bibliography{ccf}

\end{document}
